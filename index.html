<!DOCTYPE html>
<html>
<head>
    <title>Personal Introduction</title>
    <style>
        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            background-color: #D3D3D3; /* Changed the background to a light gray color */
        }
        .section {
            display: flex;
            justify-content: center;
            align-items: center;
            max-width: 80%; /* Added to reduce the width of the content */
            margin: auto; /* Added to center the content */
        }
        .intro {
            flex: 1;
        }
        .image {
            flex: 1;
        }
        img {
            max-width: 30%;
            height: auto;
        }
    </style>
</head>
<body>
    <section class="section">
        <div class="intro">
            <h1>Lincong Feng</h1>
            <p>Personal introduction: I am a third-year graduate student from Beijing University of Technology, enrolled in 2021.<br> 
            Currently, I am studying at the Multimedia and Artificial Intelligence Software Laboratory in Beijing, under the supervision of Professor Hu Yongli.<br> 
            My research focuses on multimodal learning and computer graphics, particularly in the areas of multimodal zero-shot learning and multimodal 3D asset generation.<br> 
            You can reach me at flcggm@gmail.com or 2512448518@qq.com.</p>
        </div>
        <div class="image">
            <img src="./static/images/myself.jpg" alt="Lincong Feng">
        </div>
    </section>
    <section class="section">
        <h2>Publication:</h2>
        <ul>
            <li>
                <p>Domain-aware Prototype Network for Generalized Zero-Shot Learning</p>
                <p>Yongli Hu,Lincong Feng,Hujie Jiang,Mengting Liu,Baocai Yin</p>
                <p>TCSVT 2023|<a href="https://ieeexplore.ieee.org/document/10246362">Paper</a>|<a href="project_page_url">Project Page</a>|<a href="code_url">Code</a></p>
                <img src="./static/images/DPN.png" alt="Pipeline">
            </li>
            <li>
                <p>MetaDreamer: High-Fidelity and Efficient 3D Multi-modal Reconstruction and Generation</p>
                <p>Lincong Feng,Muyu Wang,Maoyu Wang,Xiaoli Liu</p>
                <p>arxiv 2023|<a href="paper_url">Paper</a>|<a href="https://metadreamer3d.github.io/">Project Page</a>|<a href="https://github.com/fenglincong/MetaDreamer-test">Code</a></p>
                <img src="./static/images/metadreamer.png" alt="Pipeline">
            </li>
        </ul>
    </section>
</body>
</html>


